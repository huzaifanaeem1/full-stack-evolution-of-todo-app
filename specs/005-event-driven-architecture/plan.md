# Implementation Plan: Event-Driven Architecture with Kafka and Dapr

**Branch**: `005-event-driven-architecture` | **Date**: 2026-02-09 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/005-event-driven-architecture/spec.md`

## Summary

Transform the Todo system into an event-driven, loosely coupled architecture using Kafka as the message broker and Dapr as the infrastructure abstraction layer. The Chat API Service will publish task lifecycle events (created, updated, completed, deleted) to enable asynchronous processing by downstream consumer services (Recurring Task Service, Notification Service) without blocking user requests. This architecture enables service decoupling, independent scaling, and resilient asynchronous workflows while maintaining backward compatibility with existing Phase V - Part A features.

## Technical Context

**Language/Version**: Python 3.11+ (backend services), Kafka 3.x (message broker), Dapr 1.12+ (sidecar runtime)
**Primary Dependencies**: FastAPI (Chat API Service), Dapr Python SDK, Kafka (via Dapr Pub/Sub), SQLModel (database operations)
**Storage**: Neon Serverless PostgreSQL (existing), Kafka topics (event streaming)
**Testing**: pytest (unit/integration tests), Dapr CLI (local testing), Minikube (Kubernetes testing)
**Target Platform**: Kubernetes (Minikube for local development)
**Project Type**: Microservices (web application with event-driven services)
**Performance Goals**: 100 events/second throughput, <100ms event publishing latency (p95), <5 seconds event consumption latency (p95)
**Constraints**: 99.9% event delivery reliability, idempotent consumers, no direct Kafka client usage (Dapr abstraction required)
**Scale/Scope**: 3 services (1 producer, 2 consumers), 2 Kafka topics, 4 event types

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Spec-Driven Development Compliance
- [X] Specification document exists and is complete in `/specs/005-event-driven-architecture/spec.md`
- [X] Plan document will be created based on spec requirements
- [ ] Tasks will be generated from plan before implementation begins

### Technology Stack Verification
- [X] Frontend will use Next.js 16+ with App Router (no changes required for Part B)
- [X] Backend will use FastAPI framework (existing Chat API Service)
- [X] SQLModel ORM will be used for database operations (existing)
- [X] Neon Serverless PostgreSQL will be the database (existing)
- [X] Better Auth will be used for JWT-based authentication (existing)
- [X] REST API design will be followed (no GraphQL/other protocols)

### Security Requirements Check
- [X] All API endpoints will require JWT token verification (existing)
- [X] User ID will be extracted from JWT payload for data isolation (existing)
- [X] Users will only access their own data/tasks (existing)
- [X] JWT secret will be shared via environment variables only (existing)
- [X] No hardcoded secrets in source code (existing)

### Architecture Requirements
- [X] Backend and frontend will be separate deployable services (existing)
- [X] Authentication will be mandatory for all features (existing)
- [X] Data access will be user-isolated (existing)
- [X] Phase I (CLI) and Phase II (Web App) remain separate (existing)

### Phase V - Part B Specific Requirements
- [X] Dapr Pub/Sub will be used as abstraction layer for event communication
- [X] Kafka will be used as the message broker
- [X] No direct Kafka client libraries in application code
- [X] Services will communicate via events, not direct HTTP calls
- [X] Event consumers will be idempotent
- [X] Services will be stateless and independently deployable
- [X] Existing Phase V - Part A features will not be modified

## Project Structure

### Documentation (this feature)

```text
specs/005-event-driven-architecture/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (implementation plan)
├── data-model.md        # Event schemas and data structures
├── contracts/           # Event contracts and API specifications
│   ├── task-events.md   # Task event schema definitions
│   └── reminders.md     # Reminder event schema definitions
└── tasks.md             # Task breakdown (to be generated by /sp.tasks)
```

### Source Code (repository root)

```text
backend/
├── src/
│   ├── models/          # Existing task models (no changes)
│   ├── services/
│   │   ├── task_service.py      # Existing (add event publishing)
│   │   └── event_publisher.py   # NEW: Dapr event publishing service
│   ├── api/
│   │   └── tasks.py     # Existing (integrate event publishing)
│   └── config/
│       └── dapr.py      # NEW: Dapr configuration

recurring-task-service/  # NEW: Consumer service
├── src/
│   ├── main.py          # Service entry point with Dapr subscription
│   ├── handlers/
│   │   └── task_completed_handler.py  # Event handler
│   ├── services/
│   │   └── recurring_task_service.py  # Business logic
│   └── config/
│       └── dapr.py      # Dapr configuration
├── Dockerfile
└── requirements.txt

notification-service/    # NEW: Consumer service
├── src/
│   ├── main.py          # Service entry point with Dapr subscription
│   ├── handlers/
│   │   └── reminder_handler.py  # Event handler
│   ├── services/
│   │   └── notification_service.py  # Business logic
│   └── config/
│       └── dapr.py      # Dapr configuration
├── Dockerfile
└── requirements.txt

dapr/                    # NEW: Dapr configuration
├── components/
│   └── pubsub-kafka.yaml  # Kafka Pub/Sub component
└── subscriptions/
    ├── recurring-task-sub.yaml  # Recurring Task Service subscription
    └── notification-sub.yaml    # Notification Service subscription

kubernetes/              # Existing (add new services)
├── kafka/
│   ├── kafka-deployment.yaml    # NEW: Kafka broker
│   └── kafka-service.yaml       # NEW: Kafka service
├── backend/
│   └── backend-deployment.yaml  # UPDATE: Add Dapr sidecar annotations
├── recurring-task-service/      # NEW
│   ├── deployment.yaml
│   └── service.yaml
└── notification-service/        # NEW
    ├── deployment.yaml
    └── service.yaml
```

**Structure Decision**: Microservices architecture with event-driven communication. Existing backend service (Chat API Service) becomes the event producer. Two new consumer services (Recurring Task Service, Notification Service) are added as separate deployable units. Dapr sidecars are deployed alongside each service for event communication abstraction.

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

No constitution violations. All requirements align with Phase V - Part B principles.

---

## Phase 0: Research & Discovery

### Kafka Topic Design

**Topic 1: task-events**
- **Purpose**: Publish all task lifecycle events (created, updated, completed, deleted)
- **Partitioning Strategy**: Partition by user_id for ordering guarantees per user
- **Retention**: 7 days (default Kafka retention)
- **Replication Factor**: 1 (Minikube single-node), 3 (production)
- **Cleanup Policy**: Delete (time-based retention)

**Topic 2: reminders**
- **Purpose**: Publish due date reminder notifications
- **Partitioning Strategy**: Partition by user_id for ordering guarantees per user
- **Retention**: 7 days (default Kafka retention)
- **Replication Factor**: 1 (Minikube single-node), 3 (production)
- **Cleanup Policy**: Delete (time-based retention)

### Event Schema Definitions

**Task Event Schema** (task-events topic):
```json
{
  "event_id": "uuid",           // Unique event identifier for idempotency
  "event_type": "string",       // task.created | task.updated | task.completed | task.deleted
  "event_timestamp": "ISO8601", // Event generation timestamp
  "user_id": "uuid",            // User who owns the task (for data isolation)
  "task": {
    "id": "uuid",
    "title": "string",
    "description": "string",
    "is_completed": "boolean",
    "priority": "string",       // high | medium | low
    "due_date": "ISO8601",
    "is_recurring": "boolean",
    "recurrence_frequency": "string",  // daily | weekly | monthly
    "tags": ["string"],
    "created_at": "ISO8601",
    "updated_at": "ISO8601"
  }
}
```

**Reminder Event Schema** (reminders topic):
```json
{
  "event_id": "uuid",           // Unique event identifier for idempotency
  "event_type": "reminder.due_soon",
  "event_timestamp": "ISO8601", // Event generation timestamp
  "user_id": "uuid",            // User who owns the task
  "task": {
    "id": "uuid",
    "title": "string",
    "description": "string",
    "due_date": "ISO8601",
    "priority": "string"
  },
  "reminder_type": "string"     // 24_hours_before | 1_hour_before
}
```

### Dapr Pub/Sub Component Configuration

**Component Name**: pubsub-kafka
**Component Type**: pubsub.kafka
**Metadata**:
- `brokers`: kafka:9092 (Kubernetes service name)
- `consumerGroup`: Service-specific consumer group (recurring-task-service, notification-service)
- `authType`: none (Minikube), SASL (production)
- `maxMessageBytes`: 1048576 (1MB)

### Producer Responsibilities (Chat API Service)

**Service**: Chat API Service (existing backend)
**Role**: Event Producer
**Responsibilities**:
1. Publish task.created event after successful task creation
2. Publish task.updated event after successful task update
3. Publish task.completed event after successful task completion
4. Publish task.deleted event after successful task deletion
5. Handle event publishing failures gracefully (log and continue)
6. Generate unique event_id for each event (UUID)
7. Include complete task metadata in event payload
8. Publish events asynchronously without blocking user requests

**Integration Points**:
- `backend/src/services/task_service.py`: Add event publishing after database operations
- `backend/src/services/event_publisher.py`: New service for Dapr Pub/Sub interaction
- `backend/src/api/tasks.py`: No changes required (service layer handles events)

**Dapr Integration**:
- Use Dapr HTTP API: `POST http://localhost:3500/v1.0/publish/pubsub-kafka/task-events`
- Dapr sidecar handles Kafka connection, serialization, and delivery
- No direct Kafka client in application code

### Consumer Responsibilities (Recurring Task Service)

**Service**: Recurring Task Service (new)
**Role**: Event Consumer
**Responsibilities**:
1. Subscribe to task-events topic with filter: event_type = "task.completed"
2. Consume task.completed events from Kafka via Dapr
3. Check if task is recurring (is_recurring = true)
4. Calculate next due date based on recurrence_frequency
5. Create new task instance with updated due date
6. Preserve task metadata (title, description, priority, tags)
7. Set new task to incomplete status
8. Handle duplicate events idempotently (check last_recurrence_date)
9. Log processing errors and retry transient failures

**Integration Points**:
- `recurring-task-service/src/handlers/task_completed_handler.py`: Event handler
- `recurring-task-service/src/services/recurring_task_service.py`: Business logic
- Database access: Direct connection to Neon PostgreSQL (same database as Chat API Service)

**Dapr Integration**:
- Dapr subscription configuration: `/dapr/subscribe` endpoint
- Dapr delivers events via HTTP POST to `/task-completed` endpoint
- Dapr handles retry logic and dead letter queue

### Consumer Responsibilities (Notification Service)

**Service**: Notification Service (new)
**Role**: Event Consumer
**Responsibilities**:
1. Subscribe to reminders topic
2. Consume reminder events from Kafka via Dapr
3. Log notification to console with task details and user_id
4. Handle duplicate events idempotently (track processed event_ids)
5. Log processing errors and retry transient failures

**Integration Points**:
- `notification-service/src/handlers/reminder_handler.py`: Event handler
- `notification-service/src/services/notification_service.py`: Business logic
- No database access required (stateless logging)

**Dapr Integration**:
- Dapr subscription configuration: `/dapr/subscribe` endpoint
- Dapr delivers events via HTTP POST to `/reminder` endpoint
- Dapr handles retry logic and dead letter queue

### Failure and Retry Strategy

**Event Publishing Failures (Producer)**:
- **Strategy**: Best-effort delivery with logging
- **Behavior**: If Dapr sidecar is unavailable, log error and continue (user request succeeds)
- **Retry**: No automatic retry for publishing (fire-and-forget pattern)
- **Monitoring**: Log all publishing failures for manual intervention
- **Rationale**: User-facing operations must not fail due to event publishing issues

**Event Consumption Failures (Consumers)**:
- **Strategy**: Automatic retry with exponential backoff
- **Dapr Retry Policy**:
  - Initial retry delay: 1 second
  - Max retry delay: 30 seconds
  - Max retry attempts: 10
  - Backoff multiplier: 2
- **Dead Letter Queue**: After max retries, move to DLQ topic (task-events-dlq, reminders-dlq)
- **Transient Failures**: Retry automatically (database connection errors, temporary service unavailability)
- **Permanent Failures**: Move to DLQ (invalid event schema, missing required fields)
- **Monitoring**: Log all consumption failures and DLQ events

**Kafka Broker Failures**:
- **Strategy**: Dapr handles connection management and retry
- **Behavior**: Events are buffered in Dapr sidecar during Kafka unavailability
- **Recovery**: Automatic reconnection when Kafka becomes available
- **Monitoring**: Dapr metrics expose Kafka connection status

**Service Failures**:
- **Strategy**: Kubernetes restarts failed pods automatically
- **Behavior**: Unprocessed events remain in Kafka topic
- **Recovery**: Service resumes consumption from last committed offset
- **Monitoring**: Kubernetes liveness/readiness probes detect failures

### Idempotency Handling

**Producer Idempotency**:
- **Event ID**: Generate unique UUID for each event (event_id field)
- **Duplicate Prevention**: Not required at producer (Kafka handles duplicate writes)
- **Immutability**: Events are immutable once published (no updates or deletes)

**Consumer Idempotency (Recurring Task Service)**:
- **Strategy**: Check last_recurrence_date before creating new task
- **Implementation**:
  1. Query database for task by task_id
  2. Check if last_recurrence_date >= calculated next_due_date
  3. If true, skip task creation (already processed)
  4. If false, create new task and update last_recurrence_date
- **Database Transaction**: Use database transaction to ensure atomicity
- **Event ID Tracking**: Optional secondary check using event_id in processed_events table

**Consumer Idempotency (Notification Service)**:
- **Strategy**: Track processed event_ids in memory (stateless service)
- **Implementation**:
  1. Maintain in-memory set of processed event_ids (last 10,000 events)
  2. Check if event_id exists in set before logging
  3. If exists, skip logging (already processed)
  4. If not exists, log notification and add event_id to set
- **TTL**: Event IDs expire after 1 hour (sufficient for duplicate detection window)
- **Alternative**: Log duplicate notifications (acceptable for console logging)

**Kafka Offset Management**:
- **Strategy**: Commit offsets only after successful processing
- **Dapr Behavior**: Dapr commits offsets automatically after handler returns success (HTTP 200)
- **Failure Handling**: If handler returns error (HTTP 500), Dapr does not commit offset and retries
- **At-Least-Once Delivery**: Kafka guarantees at-least-once delivery, consumers must be idempotent

### Dapr Pub/Sub Usage

**Dapr Sidecar Deployment**:
- **Pattern**: Sidecar container in same Kubernetes pod as application
- **Communication**: Application communicates with Dapr via localhost HTTP/gRPC
- **Port**: Dapr HTTP API on port 3500, gRPC API on port 50001
- **Annotations**: Kubernetes deployment annotations enable Dapr injection

**Publishing Events (Producer)**:
```
POST http://localhost:3500/v1.0/publish/pubsub-kafka/task-events
Content-Type: application/json

{
  "event_id": "uuid",
  "event_type": "task.created",
  "event_timestamp": "2026-02-09T10:00:00Z",
  "user_id": "uuid",
  "task": { ... }
}
```

**Subscribing to Events (Consumer)**:
1. Implement `/dapr/subscribe` endpoint returning subscription configuration
2. Implement event handler endpoint (e.g., `/task-completed`)
3. Dapr polls `/dapr/subscribe` and registers subscriptions
4. Dapr delivers events via HTTP POST to handler endpoint

**Subscription Configuration Example**:
```json
[
  {
    "pubsubname": "pubsub-kafka",
    "topic": "task-events",
    "route": "/task-completed",
    "metadata": {
      "rawPayload": "false"
    }
  }
]
```

**Error Handling**:
- Return HTTP 200 for successful processing (Dapr commits offset)
- Return HTTP 500 for transient errors (Dapr retries)
- Return HTTP 400 for permanent errors (Dapr moves to DLQ)

### Service Communication Patterns

**Synchronous (Existing)**:
- Frontend → Chat API Service (REST API)
- User authentication and authorization
- Task CRUD operations

**Asynchronous (New)**:
- Chat API Service → Kafka (via Dapr) → Recurring Task Service
- Chat API Service → Kafka (via Dapr) → Notification Service
- No direct HTTP calls between backend services

**Data Access**:
- Chat API Service: Read/write to PostgreSQL
- Recurring Task Service: Write to PostgreSQL (create new tasks)
- Notification Service: No database access (stateless logging)

### Deployment Architecture

**Kubernetes Resources**:
1. **Kafka Deployment**: Single-node Kafka broker (Minikube)
2. **Zookeeper Deployment**: Required for Kafka coordination
3. **Chat API Service**: Existing deployment with Dapr sidecar annotations
4. **Recurring Task Service**: New deployment with Dapr sidecar
5. **Notification Service**: New deployment with Dapr sidecar
6. **Dapr Components**: ConfigMap with Kafka Pub/Sub component definition

**Dapr Sidecar Annotations** (example for Chat API Service):
```yaml
annotations:
  dapr.io/enabled: "true"
  dapr.io/app-id: "chat-api-service"
  dapr.io/app-port: "8000"
  dapr.io/config: "dapr-config"
```

**Service Discovery**:
- Kafka: kafka.default.svc.cluster.local:9092
- Services communicate via Dapr app-id (no direct service URLs)

### Testing Strategy

**Unit Tests**:
- Event publisher service (mock Dapr HTTP client)
- Event handlers (mock event payloads)
- Idempotency logic (verify duplicate handling)

**Integration Tests**:
- End-to-end event flow (publish → consume)
- Dapr local testing with Kafka container
- Database transaction verification

**System Tests**:
- Deploy to Minikube with Kafka and Dapr
- Verify event publishing from Chat API Service
- Verify event consumption by consumer services
- Test failure scenarios (Kafka down, service crash)

---

## Phase 1: Design

### Data Model

See `data-model.md` for detailed event schemas and entity relationships.

**Key Entities**:
- Task Event: Immutable event representing task lifecycle action
- Reminder Event: Immutable event representing due date reminder
- Event Topic: Kafka topic for event distribution
- Dapr Pub/Sub Component: Configuration for Kafka integration

**Event Flow**:
1. User performs task operation (create/update/complete/delete)
2. Chat API Service saves to database
3. Chat API Service publishes event to Kafka via Dapr
4. Kafka distributes event to subscribed consumers
5. Recurring Task Service consumes task.completed events
6. Notification Service consumes reminder events
7. Consumers process events and perform actions

### API Contracts

See `contracts/` directory for detailed event schemas and API specifications.

**Event Contracts**:
- `contracts/task-events.md`: Task event schema, event types, validation rules
- `contracts/reminders.md`: Reminder event schema, reminder types, validation rules

**Service Contracts**:
- Chat API Service: Existing REST API (no changes)
- Recurring Task Service: Dapr subscription endpoint, event handler
- Notification Service: Dapr subscription endpoint, event handler

### Quickstart Guide

See `quickstart.md` for step-by-step setup and testing instructions.

**Local Development Setup**:
1. Install Dapr CLI and initialize Dapr
2. Start Kafka container (Docker Compose)
3. Configure Dapr Pub/Sub component
4. Start Chat API Service with Dapr sidecar
5. Start Recurring Task Service with Dapr sidecar
6. Start Notification Service with Dapr sidecar
7. Test event flow with sample task operations

**Minikube Deployment**:
1. Deploy Kafka and Zookeeper to Minikube
2. Deploy Dapr to Minikube (dapr init -k)
3. Apply Dapr component configuration
4. Deploy Chat API Service with Dapr annotations
5. Deploy Recurring Task Service
6. Deploy Notification Service
7. Verify event flow with kubectl logs

---

## Phase 2: Task Breakdown

Task breakdown will be generated by `/sp.tasks` command based on this plan.

**Expected Task Categories**:
1. **Infrastructure Setup**: Kafka deployment, Dapr installation, component configuration
2. **Event Publisher**: Event publisher service, integration with task service
3. **Recurring Task Service**: Service implementation, event handler, idempotency logic
4. **Notification Service**: Service implementation, event handler, logging
5. **Kubernetes Deployment**: Deployment manifests, Dapr annotations, service configuration
6. **Testing**: Unit tests, integration tests, system tests
7. **Documentation**: Event schemas, API contracts, quickstart guide

---

## Risk Analysis

### Technical Risks

**Risk 1: Kafka Availability**
- **Impact**: Event publishing failures if Kafka is unavailable
- **Mitigation**: Best-effort publishing with logging, Dapr handles buffering and retry
- **Fallback**: User operations succeed even if events fail to publish

**Risk 2: Event Ordering**
- **Impact**: Events may be processed out of order across partitions
- **Mitigation**: Partition by user_id for per-user ordering guarantees
- **Fallback**: Idempotent consumers handle out-of-order events safely

**Risk 3: Duplicate Events**
- **Impact**: At-least-once delivery may cause duplicate processing
- **Mitigation**: Idempotent consumers with event_id tracking and database checks
- **Fallback**: Duplicate task creation prevented by last_recurrence_date check

**Risk 4: Consumer Lag**
- **Impact**: Consumers may fall behind during high event volume
- **Mitigation**: Horizontal scaling of consumer services, Kafka partitioning
- **Fallback**: Events remain in Kafka until processed (no data loss)

**Risk 5: Schema Evolution**
- **Impact**: Event schema changes may break consumers
- **Mitigation**: Backward-compatible schema changes, version field in events
- **Fallback**: Deploy new consumers before publishing new event versions

### Operational Risks

**Risk 1: Dapr Sidecar Overhead**
- **Impact**: Additional memory and CPU usage per service
- **Mitigation**: Monitor resource usage, adjust Kubernetes resource limits
- **Fallback**: Acceptable overhead for abstraction benefits

**Risk 2: Debugging Complexity**
- **Impact**: Distributed tracing required for event flow debugging
- **Mitigation**: Comprehensive logging, Dapr tracing integration
- **Fallback**: Kafka topic inspection for event verification

**Risk 3: Local Development Complexity**
- **Impact**: Developers need Kafka and Dapr running locally
- **Mitigation**: Docker Compose for local Kafka, Dapr CLI for local testing
- **Fallback**: Minikube for full integration testing

---

## Success Metrics

**Event Publishing**:
- 99.9% event publishing success rate
- <100ms event publishing latency (p95)
- Zero user-facing failures due to event publishing

**Event Consumption**:
- <5 seconds event consumption latency (p95)
- 100% idempotent event processing (no duplicate side effects)
- Zero data loss (all events processed or in DLQ)

**System Stability**:
- 100% backward compatibility with Phase V - Part A features
- Independent service deployment without downtime
- Graceful degradation during Kafka unavailability

**Performance**:
- 100 events/second throughput
- Horizontal scaling of consumer services
- No performance degradation of user-facing operations

---

## Appendix

### Glossary

- **Event**: Immutable message representing a state change or action
- **Producer**: Service that publishes events to Kafka
- **Consumer**: Service that subscribes to and processes events from Kafka
- **Dapr**: Distributed Application Runtime providing infrastructure abstraction
- **Pub/Sub**: Publish-Subscribe messaging pattern
- **Idempotency**: Property where processing the same event multiple times produces the same result
- **At-Least-Once Delivery**: Guarantee that events are delivered at least once (may be duplicated)
- **Consumer Group**: Group of consumers sharing event processing load
- **Offset**: Position in Kafka topic indicating last processed event
- **Dead Letter Queue**: Topic for events that failed processing after max retries

### References

- Dapr Pub/Sub Documentation: https://docs.dapr.io/developing-applications/building-blocks/pubsub/
- Kafka Documentation: https://kafka.apache.org/documentation/
- Phase V - Part B Constitution: `.specify/memory/constitution.md` (v1.3.0)
- Phase V - Part B Specification: `specs/005-event-driven-architecture/spec.md`
